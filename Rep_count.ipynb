{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329\n",
      "314\n",
      "[  3   7  11  14  19  23  28  35  39  43  46  51  59  61  64  68  70  73\n",
      "  78  81  86  88  90  94  98 103 107 111 115 120 123 126 129 131 135 140\n",
      " 144 149 152 157 162 166 168 171 176 180 184 189 193 197 201 205 209 213\n",
      " 217 222 227 231 235 239 243 245 248 252 255 260 265 269 274 279 284 288\n",
      " 291 293 299 303]\n",
      "Activity Count: 38.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import find_peaks\n",
    "from scipy import stats\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "\n",
    "def text_file_to_dataframe(file_path):\n",
    "    # Read the text file into a DataFrame\n",
    "    df = pd.read_csv(file_path, delimiter=',', header=None)\n",
    "   \n",
    "    # Split each row on commas and assign to columns\n",
    "    # df = df[0].str.split(',', expand=True)\n",
    "    headers = ['X', 'Y', 'Z', 'activity', 'user']\n",
    "    df.columns = headers\n",
    "    # print(df)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def Load_accelerometer_data(path):\n",
    "    # Collect and return the accelerometer data\n",
    "    # Replace this with your own code for data collection\n",
    "    # accelerometer_data = np.random.randn(1000, 3)  # Example random data\n",
    "    \n",
    "    df = text_file_to_dataframe(path)\n",
    "    return df\n",
    "\n",
    "def preprocess_data(accelerometer_data):\n",
    "    # Apply any necessary preprocessing steps to the accelerometer data\n",
    "    df1 = accelerometer_data.copy()\n",
    "\n",
    "    train = df1.drop(['activity', 'user'], axis=1)\n",
    "\n",
    "    test = df1.drop(train.index, axis=0)\n",
    "\n",
    "    # train.shape, test.shape\n",
    "\n",
    "    # X_train = train.drop(['activity', 'user'], axis=1)\n",
    "    # y_train = train['activity']\n",
    "    # X_test = test.drop(['activity', 'user'], axis=1)\n",
    "    # y_test = test['activity']\n",
    "    # print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "\n",
    "    # function to create time series datset for seuence modeling\n",
    "\n",
    "    def create_dataset(X, y, time_steps, step=1):\n",
    "        Xs, ys = [], []\n",
    "        for i in range(0, len(X) - time_steps, step):\n",
    "            x = X.iloc[i:(i + time_steps)].values\n",
    "            labels = y.iloc[i: i + time_steps]\n",
    "            Xs.append(x)\n",
    "            # ys.append(stats.mode(labels)[0][0])\n",
    "        return np.array(Xs), np.array(ys).reshape(-1, 1)\n",
    "\n",
    "    return train\n",
    "\n",
    "\n",
    "def remove_outliers(features):\n",
    "    # Calculate the mean and standard deviation\n",
    "    mean = np.mean(features)\n",
    "    std = np.std(features)\n",
    "    \n",
    "    # Set the threshold for outliers (e.g., 3 standard deviations away from the mean)\n",
    "    threshold = 2\n",
    "    \n",
    "    # Calculate the Z-scores for each feature\n",
    "    z_scores = [(x - mean) / std for x in features]\n",
    "    \n",
    "    # Identify the indices of outliers\n",
    "    outlier_indices = np.where(np.abs(z_scores) > threshold)[0]\n",
    "    \n",
    "    # Remove the outliers from the features array\n",
    "    filtered_features = np.delete(features, outlier_indices)\n",
    "    \n",
    "    return filtered_features\n",
    "\n",
    "\n",
    "\n",
    "def extract_features(accelerometer_data):\n",
    "    # Replace this with your own code for feature extraction\n",
    "    features = np.linalg.norm(accelerometer_data, axis=1)  # Magnitude of acceleration\n",
    "    print(len(features))\n",
    "    print(len(remove_outliers(features)))\n",
    "    return remove_outliers(features)\n",
    "\n",
    "def determine_threshold(features):\n",
    "    # Determine an appropriate threshold for peak detection\n",
    "    # Replace this with your own code for threshold determination\n",
    "    threshold =   np.mean(features)  # Example:  standard deviations\n",
    "    # print(threshold)\n",
    "    return threshold\n",
    "\n",
    "def detect_peaks(features, threshold):\n",
    "    # Detect peaks in the features using a threshold-based approach\n",
    "    peaks, _ = find_peaks(features, height=threshold)\n",
    "    return peaks\n",
    "\n",
    "def validate_peaks(peaks, accelerometer_data):\n",
    "    # Validate the detected peaks to ensure they correspond to the activity of interest\n",
    "    # Replace this with your own code for peak validation\n",
    "    print(peaks)\n",
    "    valid_peaks = peaks  # Example: no validation\n",
    "    return valid_peaks\n",
    "\n",
    "def count_activity_instances(valid_peaks):\n",
    "    # Count the number of activity instances from the valid peaks\n",
    "    activity_count = len(valid_peaks)\n",
    "    return activity_count\n",
    "\n",
    "# Main code\n",
    "accelerometer_data = Load_accelerometer_data('Crouching3_GYRO.txt')\n",
    "preprocessed_data = preprocess_data(accelerometer_data)\n",
    "features = extract_features(preprocessed_data)\n",
    "threshold = determine_threshold(features)\n",
    "peaks = detect_peaks(features, threshold)\n",
    "valid_peaks = validate_peaks(peaks, accelerometer_data)\n",
    "activity_count = count_activity_instances(valid_peaks)\n",
    "\n",
    "print(\"Activity Count:\", np.round(activity_count/2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
